import os
import json
import time
from datetime import datetime

import streamlit as st
from dotenv import load_dotenv

from preprocess import load_accidents_csv, basic_summary
from rag_engine import RAGEngine
import config  # CHUNK_SIZE, CHAT_MODEL ë“± ì„¤ì •ê°’

st.set_page_config(page_title="Accident Risk RAG", layout="wide")

LOG_PATH = "logs/latency_log.jsonl"


def log_latency(record: dict):
    """ìš”ì²­ë³„ ì§€ì—° ì‹œê°„ ë¡œê·¸ë¥¼ jsonl í˜•íƒœë¡œ ì €ì¥"""
    log_dir = os.path.dirname(LOG_PATH)
    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")


def main():
    load_dotenv()

    st.title("ğŸš¦ êµí†µì‚¬ê³  ë¦¬ìŠ¤í¬ ìš”ì•½ & ëŒ€ì‘ì „ëµ (LLM-RAG)")

    with st.sidebar:
        st.header("1) ë°ì´í„° ì—…ë¡œë“œ")
        uploaded = st.file_uploader(
            "ì‚¬ê³  ë°ì´í„° ì—…ë¡œë“œ (csv / xlsx)",
            type=["csv", "xlsx", "xls"],
        )

        st.header("2) ì§ˆë¬¸")
        question = st.text_area(
            "ì˜ˆ: ì²­ì›êµ¬ì—ì„œ ì•¼ê°„ êµì°¨ë¡œ ì‚¬ê³  ìœ„í—˜ì´ í° ì´ìœ ì™€ ëŒ€ì±…ì€?",
            height=100,
        )

        k = st.slider("ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜(k)", 2, 8, 4)

        run_btn = st.button("ë¶„ì„ ì‹¤í–‰")

    # RAG ë¡œë“œ
    rag = RAGEngine()
    try:
        rag.load()  # ê¸°ì¡´ì— ì“°ë˜ ë©”ì„œë“œ ìœ ì§€
    except Exception as e:
        st.warning("ì§€ì‹ ì¸ë±ìŠ¤ê°€ ì—†ì–´ ë³´ì—¬. ë¨¼ì € `python ingest.py` ì‹¤í–‰í•´ì¤˜.")
        st.stop()

    if run_btn:
        if uploaded is None:
            st.error("CSVë¥¼ ì—…ë¡œë“œí•´ì¤˜.")
            st.stop()

        if not question.strip():
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì¤˜.")
            st.stop()

        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘
        start_total = time.time()

        # ğŸ”´ íŒŒì¼ ë¡œë”© ì—ëŸ¬ë¥¼ í™”ë©´ì—ì„œ ë³´ì—¬ì£¼ê¸°
        try:
            df = load_accidents_csv(uploaded)
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´: {e}")
            st.stop()

        stats = basic_summary(df)

        st.subheader("ğŸ“Œ ë°ì´í„° ìš”ì•½")
        st.json(stats)

        # Retrieval ì‹œê°„ ì¸¡ì •
        start_retrieval = time.time()
        retrieved = rag.retrieve(question, k=k)
        end_retrieval = time.time()

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“š ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸")
            for i, c in enumerate(retrieved, 1):
                st.markdown(f"**#{i}**")
                st.write(c)

        with col2:
            st.subheader("ğŸ¤– LLM ë‹µë³€")
            start_llm = time.time()
            answer = rag.answer(question, stats, retrieved)
            end_llm = time.time()
            st.write(answer)

        end_total = time.time()

        # ì§€ì—° ì‹œê°„ ë¡œê·¸ ì €ì¥ (ms ë‹¨ìœ„)
        log_latency(
            {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "retrieval_ms": int((end_retrieval - start_retrieval) * 1000),
                "llm_ms": int((end_llm - start_llm) * 1000),
                "total_ms": int((end_total - start_total) * 1000),
                "top_k": k,
                "chunk_size": getattr(config, "CHUNK_SIZE", None),
                "model": getattr(config, "CHAT_MODEL", None),
            }
        )


if __name__ == "__main__":
    main()
